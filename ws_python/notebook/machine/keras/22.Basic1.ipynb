{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential # Class\n",
    "from keras.layers import Dense # Class\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,15,16,17,18,19,20])\n",
    "y_train = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.sequential.Sequential'>\n",
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 147.7537 - acc: 0.0000e+00 - val_loss: 537.9098 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 144.5998 - acc: 0.0000e+00 - val_loss: 526.2502 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 141.4043 - acc: 0.0000e+00 - val_loss: 515.1815 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 138.4007 - acc: 0.0000e+00 - val_loss: 504.2621 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 135.2809 - acc: 0.0000e+00 - val_loss: 494.1074 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 132.4822 - acc: 0.0000e+00 - val_loss: 483.3246 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 129.3775 - acc: 0.0000e+00 - val_loss: 473.8931 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 126.7804 - acc: 0.0000e+00 - val_loss: 463.1490 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 123.8721 - acc: 0.0000e+00 - val_loss: 453.3391 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 120.9740 - acc: 0.0000e+00 - val_loss: 444.6145 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 118.4915 - acc: 0.0000e+00 - val_loss: 434.4613 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 115.7677 - acc: 0.0000e+00 - val_loss: 424.9165 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 113.2742 - acc: 0.0000e+00 - val_loss: 415.1181 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 110.5541 - acc: 0.0000e+00 - val_loss: 406.2652 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 107.9372 - acc: 0.0000e+00 - val_loss: 398.1988 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 105.5833 - acc: 0.0000e+00 - val_loss: 389.4565 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 103.3229 - acc: 0.0000e+00 - val_loss: 379.9878 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 100.6321 - acc: 0.0000e+00 - val_loss: 372.4127 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 98.4855 - acc: 0.0000e+00 - val_loss: 363.7022 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 96.0702 - acc: 0.0000e+00 - val_loss: 355.7815 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 93.8263 - acc: 0.0000e+00 - val_loss: 347.8928 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 91.6556 - acc: 0.0000e+00 - val_loss: 339.8329 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 89.6107 - acc: 0.0000e+00 - val_loss: 331.3309 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 87.1809 - acc: 0.0000e+00 - val_loss: 324.4860 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 85.2902 - acc: 0.0000e+00 - val_loss: 316.5686 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 83.1384 - acc: 0.0000e+00 - val_loss: 309.2135 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 81.0763 - acc: 0.0000e+00 - val_loss: 302.1971 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 79.0666 - acc: 0.0000e+00 - val_loss: 295.4629 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 77.1686 - acc: 0.0000e+00 - val_loss: 288.5448 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 75.2393 - acc: 0.0000e+00 - val_loss: 281.7978 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 73.4189 - acc: 0.0000e+00 - val_loss: 274.8913 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 71.5645 - acc: 0.0000e+00 - val_loss: 268.1733 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 69.7349 - acc: 0.0625 - val_loss: 261.6934 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 68.0483 - acc: 0.0625 - val_loss: 255.0291 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 66.1209 - acc: 0.0625 - val_loss: 249.5166 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 64.6841 - acc: 0.0625 - val_loss: 242.7692 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 62.8110 - acc: 0.0625 - val_loss: 237.0934 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 61.2806 - acc: 0.0625 - val_loss: 230.9840 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 59.5502 - acc: 0.0625 - val_loss: 225.6850 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 58.0501 - acc: 0.0625 - val_loss: 220.0990 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 56.4912 - acc: 0.0625 - val_loss: 214.7176 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 54.9603 - acc: 0.0625 - val_loss: 209.6325 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 53.5749 - acc: 0.0625 - val_loss: 204.0642 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 52.2217 - acc: 0.0625 - val_loss: 198.2391 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 50.5830 - acc: 0.0625 - val_loss: 193.6351 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 49.2385 - acc: 0.0625 - val_loss: 188.9805 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 47.9417 - acc: 0.0625 - val_loss: 183.9699 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 46.7044 - acc: 0.0625 - val_loss: 178.6698 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 45.2602 - acc: 0.0625 - val_loss: 174.2111 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 44.0525 - acc: 0.0625 - val_loss: 169.4741 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 42.7426 - acc: 0.0625 - val_loss: 165.2718 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 41.6629 - acc: 0.0625 - val_loss: 160.4391 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 40.3265 - acc: 0.0625 - val_loss: 156.4605 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 39.1947 - acc: 0.0625 - val_loss: 152.3846 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 38.0983 - acc: 0.0625 - val_loss: 148.2115 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 36.9509 - acc: 0.0625 - val_loss: 144.2954 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 35.9373 - acc: 0.0625 - val_loss: 140.0630 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 34.7719 - acc: 0.0625 - val_loss: 136.5678 - val_acc: 0.0000e+00\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 33.8847 - acc: 0.0625 - val_loss: 132.3070 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 32.7209 - acc: 0.0625 - val_loss: 128.9934 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 31.8183 - acc: 0.0625 - val_loss: 125.2257 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 30.8442 - acc: 0.0625 - val_loss: 121.6109 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 29.9241 - acc: 0.0625 - val_loss: 117.9745 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 29.0133 - acc: 0.0625 - val_loss: 114.4380 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 28.0036 - acc: 0.1250 - val_loss: 111.5991 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 27.2072 - acc: 0.1250 - val_loss: 108.3375 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 26.3132 - acc: 0.1250 - val_loss: 105.4324 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 25.5404 - acc: 0.1250 - val_loss: 102.2148 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24.6947 - acc: 0.1250 - val_loss: 99.2734 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 23.9636 - acc: 0.1250 - val_loss: 96.0996 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 23.1235 - acc: 0.1250 - val_loss: 93.3815 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 22.4041 - acc: 0.1250 - val_loss: 90.5614 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 21.6502 - acc: 0.1250 - val_loss: 87.9437 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 20.9574 - acc: 0.1250 - val_loss: 85.2996 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 20.2769 - acc: 0.1250 - val_loss: 82.6156 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 19.5603 - acc: 0.1250 - val_loss: 80.3037 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 19.0085 - acc: 0.1250 - val_loss: 77.4603 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.2844 - acc: 0.1250 - val_loss: 75.1267 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 17.6644 - acc: 0.1250 - val_loss: 72.8403 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 17.0665 - acc: 0.1250 - val_loss: 70.5814 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 16.4619 - acc: 0.1250 - val_loss: 68.5125 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 15.9206 - acc: 0.1250 - val_loss: 66.2932 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 15.3834 - acc: 0.1250 - val_loss: 64.0524 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14.7981 - acc: 0.1250 - val_loss: 62.1483 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 14.2815 - acc: 0.1250 - val_loss: 60.2631 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13.8046 - acc: 0.1875 - val_loss: 58.2131 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 13.3002 - acc: 0.1875 - val_loss: 56.2914 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12.7905 - acc: 0.1875 - val_loss: 54.6690 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12.3831 - acc: 0.1875 - val_loss: 52.6958 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 11.8973 - acc: 0.1250 - val_loss: 50.9991 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 11.4641 - acc: 0.1250 - val_loss: 49.3072 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 11.0516 - acc: 0.1250 - val_loss: 47.6002 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 10.6383 - acc: 0.1250 - val_loss: 45.9749 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 10.2267 - acc: 0.1250 - val_loss: 44.4751 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 9.8471 - acc: 0.1250 - val_loss: 42.9697 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 9.4734 - acc: 0.1250 - val_loss: 41.5290 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 9.1066 - acc: 0.1250 - val_loss: 40.1591 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 8.7843 - acc: 0.1250 - val_loss: 38.6713 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 8.4233 - acc: 0.1250 - val_loss: 37.3675 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 8.0900 - acc: 0.1250 - val_loss: 36.1375 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.7883 - acc: 0.1875 - val_loss: 34.8567 - val_acc: 0.0000e+00\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.4702 - acc: 0.1875 - val_loss: 33.6865 - val_acc: 0.0000e+00\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.1820 - acc: 0.1875 - val_loss: 32.5105 - val_acc: 0.0000e+00\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.9184 - acc: 0.1875 - val_loss: 31.2476 - val_acc: 0.0000e+00\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.6084 - acc: 0.1875 - val_loss: 30.2327 - val_acc: 0.0000e+00\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.3757 - acc: 0.1875 - val_loss: 29.0538 - val_acc: 0.0000e+00\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 6.0955 - acc: 0.1875 - val_loss: 28.0460 - val_acc: 0.0000e+00\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.8484 - acc: 0.1875 - val_loss: 27.0619 - val_acc: 0.0000e+00\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.6074 - acc: 0.1875 - val_loss: 26.1350 - val_acc: 0.0000e+00\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.3886 - acc: 0.1875 - val_loss: 25.1558 - val_acc: 0.0000e+00\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.1627 - acc: 0.1875 - val_loss: 24.2500 - val_acc: 0.0000e+00\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.9440 - acc: 0.1875 - val_loss: 23.3922 - val_acc: 0.0000e+00\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 4.7411 - acc: 0.1875 - val_loss: 22.5435 - val_acc: 0.0000e+00\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 4.5393 - acc: 0.2500 - val_loss: 21.7708 - val_acc: 0.0000e+00\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 4.3594 - acc: 0.2500 - val_loss: 20.9295 - val_acc: 0.0000e+00\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 4.1757 - acc: 0.2500 - val_loss: 20.1172 - val_acc: 0.0000e+00\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 3.9873 - acc: 0.2500 - val_loss: 19.4219 - val_acc: 0.0000e+00\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.8359 - acc: 0.1875 - val_loss: 18.6231 - val_acc: 0.0000e+00\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.6600 - acc: 0.1875 - val_loss: 17.9401 - val_acc: 0.0000e+00\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.5076 - acc: 0.1875 - val_loss: 17.2523 - val_acc: 0.0000e+00\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.3505 - acc: 0.1875 - val_loss: 16.6310 - val_acc: 0.0000e+00\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.2105 - acc: 0.1875 - val_loss: 16.0000 - val_acc: 0.0000e+00\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.0642 - acc: 0.1875 - val_loss: 15.4616 - val_acc: 0.0000e+00\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 2.9382 - acc: 0.1875 - val_loss: 14.8887 - val_acc: 0.0000e+00\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.8248 - acc: 0.2500 - val_loss: 14.2417 - val_acc: 0.0000e+00\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.6839 - acc: 0.2500 - val_loss: 13.7600 - val_acc: 0.0000e+00\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.5868 - acc: 0.2500 - val_loss: 13.1527 - val_acc: 0.0000e+00\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.4579 - acc: 0.2500 - val_loss: 12.6770 - val_acc: 0.0000e+00\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.3537 - acc: 0.2500 - val_loss: 12.1946 - val_acc: 0.0000e+00\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.2460 - acc: 0.2500 - val_loss: 11.7756 - val_acc: 0.0000e+00\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.1550 - acc: 0.2500 - val_loss: 11.3113 - val_acc: 0.0000e+00\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.0677 - acc: 0.2500 - val_loss: 10.8276 - val_acc: 0.0000e+00\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.9692 - acc: 0.2500 - val_loss: 10.4214 - val_acc: 0.0000e+00\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.8797 - acc: 0.3125 - val_loss: 10.0596 - val_acc: 0.0000e+00\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.8037 - acc: 0.3125 - val_loss: 9.6706 - val_acc: 0.0000e+00\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.7294 - acc: 0.3125 - val_loss: 9.2728 - val_acc: 0.0000e+00\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.6509 - acc: 0.3125 - val_loss: 8.9198 - val_acc: 0.0000e+00\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5786 - acc: 0.3125 - val_loss: 8.5907 - val_acc: 0.0000e+00\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.5117 - acc: 0.2500 - val_loss: 8.2680 - val_acc: 0.0000e+00\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.4502 - acc: 0.2500 - val_loss: 7.9394 - val_acc: 0.0000e+00\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.3886 - acc: 0.2500 - val_loss: 7.6252 - val_acc: 0.0000e+00\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3310 - acc: 0.2500 - val_loss: 7.3209 - val_acc: 0.0000e+00\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2781 - acc: 0.3125 - val_loss: 7.0196 - val_acc: 0.0000e+00\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.2176 - acc: 0.3125 - val_loss: 6.7805 - val_acc: 0.0000e+00\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1721 - acc: 0.3125 - val_loss: 6.5159 - val_acc: 0.0000e+00\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.1204 - acc: 0.3125 - val_loss: 6.3047 - val_acc: 0.0000e+00\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0776 - acc: 0.3125 - val_loss: 6.0778 - val_acc: 0.0000e+00\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0368 - acc: 0.3125 - val_loss: 5.8417 - val_acc: 0.0000e+00\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.9949 - acc: 0.3125 - val_loss: 5.6221 - val_acc: 0.0000e+00\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9596 - acc: 0.3125 - val_loss: 5.3825 - val_acc: 0.0000e+00\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9176 - acc: 0.3750 - val_loss: 5.2017 - val_acc: 0.0000e+00\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8851 - acc: 0.3750 - val_loss: 5.0045 - val_acc: 0.0000e+00\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8541 - acc: 0.3750 - val_loss: 4.8010 - val_acc: 0.0000e+00\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8233 - acc: 0.3750 - val_loss: 4.6052 - val_acc: 0.0000e+00\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7902 - acc: 0.3750 - val_loss: 4.4474 - val_acc: 0.0000e+00\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7643 - acc: 0.3750 - val_loss: 4.2821 - val_acc: 0.0000e+00\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7364 - acc: 0.3750 - val_loss: 4.1374 - val_acc: 0.0000e+00\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7133 - acc: 0.3125 - val_loss: 3.9844 - val_acc: 0.0000e+00\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6900 - acc: 0.3125 - val_loss: 3.8364 - val_acc: 0.0000e+00\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6670 - acc: 0.3750 - val_loss: 3.7053 - val_acc: 0.0000e+00\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6469 - acc: 0.3750 - val_loss: 3.5704 - val_acc: 0.0000e+00\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6271 - acc: 0.3750 - val_loss: 3.4431 - val_acc: 0.0000e+00\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6092 - acc: 0.3750 - val_loss: 3.3167 - val_acc: 0.0000e+00\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5918 - acc: 0.3750 - val_loss: 3.1942 - val_acc: 0.0000e+00\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5748 - acc: 0.3750 - val_loss: 3.0811 - val_acc: 0.0000e+00\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5576 - acc: 0.3750 - val_loss: 3.0068 - val_acc: 0.0000e+00\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.5479 - acc: 0.3750 - val_loss: 2.8757 - val_acc: 0.0000e+00\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5317 - acc: 0.4375 - val_loss: 2.7738 - val_acc: 0.0000e+00\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5170 - acc: 0.4375 - val_loss: 2.6922 - val_acc: 0.0000e+00\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5054 - acc: 0.4375 - val_loss: 2.6090 - val_acc: 0.0000e+00\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4942 - acc: 0.4375 - val_loss: 2.5391 - val_acc: 0.0000e+00\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4854 - acc: 0.4375 - val_loss: 2.4412 - val_acc: 0.0000e+00\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4739 - acc: 0.4375 - val_loss: 2.3628 - val_acc: 0.0000e+00\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4640 - acc: 0.4375 - val_loss: 2.2998 - val_acc: 0.0000e+00\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4551 - acc: 0.4375 - val_loss: 2.2348 - val_acc: 0.0000e+00\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4476 - acc: 0.4375 - val_loss: 2.1583 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4397 - acc: 0.4375 - val_loss: 2.0865 - val_acc: 0.0000e+00\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4314 - acc: 0.5000 - val_loss: 2.0385 - val_acc: 0.0000e+00\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4257 - acc: 0.4375 - val_loss: 1.9686 - val_acc: 0.0000e+00\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4194 - acc: 0.4375 - val_loss: 1.9028 - val_acc: 0.0000e+00\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4123 - acc: 0.4375 - val_loss: 1.8522 - val_acc: 0.0000e+00\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4067 - acc: 0.4375 - val_loss: 1.8064 - val_acc: 0.0000e+00\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.4016 - acc: 0.4375 - val_loss: 1.7687 - val_acc: 0.0000e+00\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3982 - acc: 0.4375 - val_loss: 1.7020 - val_acc: 0.0000e+00\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3917 - acc: 0.4375 - val_loss: 1.6589 - val_acc: 0.0000e+00\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3885 - acc: 0.4375 - val_loss: 1.6065 - val_acc: 0.0000e+00\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3830 - acc: 0.4375 - val_loss: 1.5795 - val_acc: 0.0000e+00\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3793 - acc: 0.4375 - val_loss: 1.5510 - val_acc: 0.0000e+00\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3762 - acc: 0.4375 - val_loss: 1.5051 - val_acc: 0.0000e+00\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3725 - acc: 0.5000 - val_loss: 1.4762 - val_acc: 0.0000e+00\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3706 - acc: 0.5000 - val_loss: 1.4233 - val_acc: 0.0000e+00\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3659 - acc: 0.5000 - val_loss: 1.3951 - val_acc: 0.0000e+00\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3636 - acc: 0.5000 - val_loss: 1.3612 - val_acc: 0.0000e+00\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3613 - acc: 0.5000 - val_loss: 1.3247 - val_acc: 0.0000e+00\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3577 - acc: 0.5000 - val_loss: 1.3040 - val_acc: 0.0000e+00\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3556 - acc: 0.5000 - val_loss: 1.2769 - val_acc: 0.0000e+00\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3532 - acc: 0.5000 - val_loss: 1.2525 - val_acc: 0.0000e+00\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3512 - acc: 0.5000 - val_loss: 1.2325 - val_acc: 0.0000e+00\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3491 - acc: 0.5000 - val_loss: 1.2058 - val_acc: 0.0000e+00\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3474 - acc: 0.5000 - val_loss: 1.1784 - val_acc: 0.0000e+00\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3453 - acc: 0.5000 - val_loss: 1.1592 - val_acc: 0.0000e+00\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3436 - acc: 0.5000 - val_loss: 1.1355 - val_acc: 0.0000e+00\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3416 - acc: 0.5000 - val_loss: 1.1193 - val_acc: 0.0000e+00\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3404 - acc: 0.5000 - val_loss: 1.1057 - val_acc: 0.0000e+00\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3392 - acc: 0.5625 - val_loss: 1.0766 - val_acc: 0.0000e+00\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3372 - acc: 0.5625 - val_loss: 1.0577 - val_acc: 0.0000e+00\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3356 - acc: 0.5625 - val_loss: 1.0465 - val_acc: 0.0000e+00\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3344 - acc: 0.5625 - val_loss: 1.0319 - val_acc: 0.0000e+00\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3330 - acc: 0.5625 - val_loss: 1.0126 - val_acc: 0.0000e+00\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3317 - acc: 0.5625 - val_loss: 0.9948 - val_acc: 0.0000e+00\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3305 - acc: 0.5625 - val_loss: 0.9787 - val_acc: 0.0000e+00\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3292 - acc: 0.5625 - val_loss: 0.9775 - val_acc: 0.0000e+00\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3281 - acc: 0.5625 - val_loss: 0.9590 - val_acc: 0.0000e+00\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3267 - acc: 0.5625 - val_loss: 0.9518 - val_acc: 0.0000e+00\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3262 - acc: 0.5625 - val_loss: 0.9323 - val_acc: 0.0000e+00\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3246 - acc: 0.5625 - val_loss: 0.9221 - val_acc: 0.0000e+00\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3234 - acc: 0.5625 - val_loss: 0.9085 - val_acc: 0.0000e+00\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3224 - acc: 0.5625 - val_loss: 0.9059 - val_acc: 0.0000e+00\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3213 - acc: 0.5625 - val_loss: 0.8914 - val_acc: 0.0000e+00\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3202 - acc: 0.5625 - val_loss: 0.8829 - val_acc: 0.0000e+00\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3190 - acc: 0.5625 - val_loss: 0.8738 - val_acc: 0.0000e+00\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3185 - acc: 0.5625 - val_loss: 0.8724 - val_acc: 0.0000e+00\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3169 - acc: 0.5625 - val_loss: 0.8601 - val_acc: 0.0000e+00\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3162 - acc: 0.5625 - val_loss: 0.8504 - val_acc: 0.0000e+00\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3151 - acc: 0.5625 - val_loss: 0.8375 - val_acc: 0.0000e+00\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3141 - acc: 0.5625 - val_loss: 0.8243 - val_acc: 0.0000e+00\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3130 - acc: 0.5625 - val_loss: 0.8174 - val_acc: 0.0000e+00\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3121 - acc: 0.5625 - val_loss: 0.8137 - val_acc: 0.0000e+00\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3111 - acc: 0.5625 - val_loss: 0.8113 - val_acc: 0.0000e+00\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3100 - acc: 0.5625 - val_loss: 0.8045 - val_acc: 0.0000e+00\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3095 - acc: 0.5625 - val_loss: 0.8035 - val_acc: 0.0000e+00\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3085 - acc: 0.5625 - val_loss: 0.7834 - val_acc: 0.0000e+00\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3077 - acc: 0.6250 - val_loss: 0.7887 - val_acc: 0.0000e+00\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3063 - acc: 0.6250 - val_loss: 0.7729 - val_acc: 0.0000e+00\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3053 - acc: 0.6250 - val_loss: 0.7768 - val_acc: 0.0000e+00\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3042 - acc: 0.6250 - val_loss: 0.7723 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3032 - acc: 0.6250 - val_loss: 0.7612 - val_acc: 0.0000e+00\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3024 - acc: 0.6250 - val_loss: 0.7605 - val_acc: 0.0000e+00\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3013 - acc: 0.6250 - val_loss: 0.7565 - val_acc: 0.0000e+00\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3003 - acc: 0.6250 - val_loss: 0.7431 - val_acc: 0.0000e+00\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2992 - acc: 0.6250 - val_loss: 0.7354 - val_acc: 0.0000e+00\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2984 - acc: 0.6250 - val_loss: 0.7337 - val_acc: 0.0000e+00\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2975 - acc: 0.6250 - val_loss: 0.7246 - val_acc: 0.0000e+00\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2962 - acc: 0.6250 - val_loss: 0.7275 - val_acc: 0.0000e+00\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2952 - acc: 0.6250 - val_loss: 0.7314 - val_acc: 0.0000e+00\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2945 - acc: 0.6250 - val_loss: 0.7182 - val_acc: 0.0000e+00\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2933 - acc: 0.6250 - val_loss: 0.7157 - val_acc: 0.0000e+00\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2922 - acc: 0.6250 - val_loss: 0.7130 - val_acc: 0.0000e+00\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2913 - acc: 0.6250 - val_loss: 0.7032 - val_acc: 0.0000e+00\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2903 - acc: 0.6250 - val_loss: 0.7111 - val_acc: 0.0000e+00\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2895 - acc: 0.6250 - val_loss: 0.6967 - val_acc: 0.0000e+00\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2885 - acc: 0.6250 - val_loss: 0.6892 - val_acc: 0.0000e+00\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2872 - acc: 0.6250 - val_loss: 0.6887 - val_acc: 0.0000e+00\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2860 - acc: 0.6250 - val_loss: 0.6895 - val_acc: 0.0000e+00\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2850 - acc: 0.6250 - val_loss: 0.6899 - val_acc: 0.0000e+00\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2840 - acc: 0.6250 - val_loss: 0.6826 - val_acc: 0.0000e+00\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2829 - acc: 0.6250 - val_loss: 0.6789 - val_acc: 0.0000e+00\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2820 - acc: 0.6250 - val_loss: 0.6740 - val_acc: 0.0000e+00\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2810 - acc: 0.6250 - val_loss: 0.6718 - val_acc: 0.0000e+00\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2797 - acc: 0.6250 - val_loss: 0.6686 - val_acc: 0.0000e+00\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2787 - acc: 0.6250 - val_loss: 0.6742 - val_acc: 0.0000e+00\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2775 - acc: 0.6250 - val_loss: 0.6695 - val_acc: 0.0000e+00\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2765 - acc: 0.6250 - val_loss: 0.6663 - val_acc: 0.0000e+00\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2755 - acc: 0.6250 - val_loss: 0.6644 - val_acc: 0.0000e+00\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2746 - acc: 0.6250 - val_loss: 0.6644 - val_acc: 0.0000e+00\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2733 - acc: 0.6250 - val_loss: 0.6621 - val_acc: 0.0000e+00\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2723 - acc: 0.6250 - val_loss: 0.6506 - val_acc: 0.0000e+00\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2712 - acc: 0.6250 - val_loss: 0.6534 - val_acc: 0.0000e+00\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2700 - acc: 0.6250 - val_loss: 0.6439 - val_acc: 0.0000e+00\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2689 - acc: 0.6250 - val_loss: 0.6419 - val_acc: 0.0000e+00\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2679 - acc: 0.6250 - val_loss: 0.6436 - val_acc: 0.0000e+00\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2668 - acc: 0.6250 - val_loss: 0.6418 - val_acc: 0.0000e+00\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2657 - acc: 0.6250 - val_loss: 0.6299 - val_acc: 0.0000e+00\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2646 - acc: 0.6250 - val_loss: 0.6294 - val_acc: 0.0000e+00\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2634 - acc: 0.6250 - val_loss: 0.6274 - val_acc: 0.0000e+00\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2623 - acc: 0.6250 - val_loss: 0.6237 - val_acc: 0.0000e+00\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2612 - acc: 0.6250 - val_loss: 0.6171 - val_acc: 0.0000e+00\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2601 - acc: 0.6250 - val_loss: 0.6135 - val_acc: 0.0000e+00\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2589 - acc: 0.6250 - val_loss: 0.6152 - val_acc: 0.0000e+00\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2579 - acc: 0.6250 - val_loss: 0.6125 - val_acc: 0.0000e+00\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2570 - acc: 0.6250 - val_loss: 0.6189 - val_acc: 0.0000e+00\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2556 - acc: 0.6250 - val_loss: 0.6135 - val_acc: 0.0000e+00\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2545 - acc: 0.6250 - val_loss: 0.6024 - val_acc: 0.0000e+00\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2535 - acc: 0.6250 - val_loss: 0.6042 - val_acc: 0.0000e+00\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2523 - acc: 0.6250 - val_loss: 0.6073 - val_acc: 0.0000e+00\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2510 - acc: 0.6250 - val_loss: 0.6004 - val_acc: 0.0000e+00\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.6250 - val_loss: 0.6006 - val_acc: 0.0000e+00\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2489 - acc: 0.6250 - val_loss: 0.6009 - val_acc: 0.0000e+00\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2478 - acc: 0.6250 - val_loss: 0.5812 - val_acc: 0.0000e+00\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2469 - acc: 0.6250 - val_loss: 0.5915 - val_acc: 0.0000e+00\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2452 - acc: 0.6250 - val_loss: 0.5805 - val_acc: 0.0000e+00\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2442 - acc: 0.6250 - val_loss: 0.5700 - val_acc: 0.0000e+00\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2428 - acc: 0.6250 - val_loss: 0.5677 - val_acc: 0.0000e+00\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2417 - acc: 0.6250 - val_loss: 0.5693 - val_acc: 0.0000e+00\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2406 - acc: 0.6250 - val_loss: 0.5645 - val_acc: 0.0000e+00\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2394 - acc: 0.6250 - val_loss: 0.5646 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2382 - acc: 0.6250 - val_loss: 0.5638 - val_acc: 0.0000e+00\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2370 - acc: 0.6250 - val_loss: 0.5636 - val_acc: 0.0000e+00\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2358 - acc: 0.6250 - val_loss: 0.5574 - val_acc: 0.0000e+00\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2346 - acc: 0.6250 - val_loss: 0.5515 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# 하나의 은닉층을 사용하는 경우\n",
    "model = Sequential()\n",
    "print(type(model)) ## Class 첫자 대문자 Dense\n",
    "# 입력값 : input_shape\n",
    "# 1 출력갯수\n",
    "# 활성화 함수 : linear\n",
    "#model.add(Dense(1,input_shape=(1,), activation='linear')) # 배열 선언\n",
    "model.add(Dense( 1, input_dim=1, activation='linear')) # 입력갯수\n",
    "model.compile( optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# 학습 validation_split=0.2 검증과정에서  사용(4건)\n",
    "# 전체데이터를 대상으로 한 학습지수 epochs\n",
    "# batch_size : 전체데이터를 사용하면 메모리 부족현상, 데이터를 분할하여 학습하는 기법, 가중치 변경\n",
    "# 총 가중치 변경 : epochs * batch_size : 1*300=300\n",
    "hist = model.fit( x_train, y_train,validation_split=0.2, epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# 파라메터\n",
    "# 하이퍼 파라메터 : 학습에 사용되는 파라메터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "font_name = font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "# windows 10\n",
    "# font_name = font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgunsl.ttf\").get_name()\n",
    "rc('font', family=font_name)           # 맑은 고딕 폰트 지정\n",
    "plt.rcParams[\"font.size\"] = 12         # 글자 크기\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 4) # 10:4의 그래프 비율\n",
    "plt.rcParams['axes.unicode_minus'] = False  # minus 부호는 unicode 적용시 한글이 깨짐으로 설정\n",
    "\n",
    "# Jupyter에게 matplotlib 그래프를 출력 영역에 표시할 것을 지시하는 명령\n",
    "%matplotlib inline  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 125.0]) # 값을 반영하여 변경\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "# 여러 은닉층을 사용하는 경우\n",
    "model = Sequential()\n",
    "print(type(model)) ## Class 첫자 대문자 Dense\n",
    "# 입력값 : input_shape\n",
    "# 10 출력갯수\n",
    "# 활성화 함수 : linear\n",
    "#model.add(Dense(10,input_shape=(1,), activation='linear')) # 배열 선언\n",
    "model.add(Dense(10,input_dim=1, activation='linear')) # 입력갯수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential  # class\n",
    "from keras.layers import Dense       \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40]\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,15,16,17,18,19,20])\n",
    "y_train = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40])\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.sequential.Sequential'>\n",
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 34.8491 - acc: 0.0000e+00 - val_loss: 125.2969 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 33.2464 - acc: 0.0000e+00 - val_loss: 120.2299 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 31.9457 - acc: 0.0000e+00 - val_loss: 114.5964 - val_acc: 0.0000e+00\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 30.4123 - acc: 0.0000e+00 - val_loss: 109.7507 - val_acc: 0.0000e+00\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 29.1220 - acc: 0.0625 - val_loss: 104.8242 - val_acc: 0.0000e+00\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 27.6957 - acc: 0.0625 - val_loss: 100.5896 - val_acc: 0.0000e+00\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 26.5199 - acc: 0.0625 - val_loss: 95.9867 - val_acc: 0.0000e+00\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 25.2179 - acc: 0.0625 - val_loss: 91.9624 - val_acc: 0.0000e+00\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 24.1066 - acc: 0.0625 - val_loss: 87.6293 - val_acc: 0.0000e+00\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 22.9557 - acc: 0.0625 - val_loss: 83.5408 - val_acc: 0.0000e+00\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 21.8448 - acc: 0.0625 - val_loss: 79.6841 - val_acc: 0.0000e+00\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 20.7387 - acc: 0.0625 - val_loss: 76.2429 - val_acc: 0.0000e+00\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 19.7689 - acc: 0.0625 - val_loss: 72.6075 - val_acc: 0.0000e+00\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 18.7739 - acc: 0.0625 - val_loss: 69.2112 - val_acc: 0.0000e+00\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 17.8773 - acc: 0.0625 - val_loss: 65.7246 - val_acc: 0.0000e+00\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 16.8912 - acc: 0.0625 - val_loss: 62.8217 - val_acc: 0.0000e+00\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 16.0565 - acc: 0.0625 - val_loss: 59.8420 - val_acc: 0.0000e+00\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 15.2336 - acc: 0.0625 - val_loss: 56.8723 - val_acc: 0.0000e+00\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 14.5022 - acc: 0.0625 - val_loss: 53.7237 - val_acc: 0.0000e+00\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 13.6285 - acc: 0.0625 - val_loss: 51.2608 - val_acc: 0.0000e+00\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 3.0536 - acc: 0.0000e+0 - 0s 1ms/step - loss: 12.9747 - acc: 0.0625 - val_loss: 48.4576 - val_acc: 0.0000e+00\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 12.2273 - acc: 0.1250 - val_loss: 46.0105 - val_acc: 0.0000e+00\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 11.5256 - acc: 0.1250 - val_loss: 43.9022 - val_acc: 0.0000e+00\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 10.9880 - acc: 0.1250 - val_loss: 41.2695 - val_acc: 0.0000e+00\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 10.2814 - acc: 0.1250 - val_loss: 39.2513 - val_acc: 0.0000e+00\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 9.7540 - acc: 0.1250 - val_loss: 37.0005 - val_acc: 0.0000e+00\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 9.1607 - acc: 0.1250 - val_loss: 35.0357 - val_acc: 0.0000e+00\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 8.6303 - acc: 0.1250 - val_loss: 33.1490 - val_acc: 0.0000e+00\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 8.1430 - acc: 0.1250 - val_loss: 31.2618 - val_acc: 0.0000e+00\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6421 - acc: 0.1250 - val_loss: 29.5535 - val_acc: 0.0000e+00\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.1530 - acc: 0.1250 - val_loss: 28.1797 - val_acc: 0.0000e+00\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.7941 - acc: 0.1250 - val_loss: 26.3681 - val_acc: 0.0000e+00\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 6.3366 - acc: 0.1250 - val_loss: 24.8790 - val_acc: 0.0000e+00\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 5.9388 - acc: 0.1875 - val_loss: 23.4790 - val_acc: 0.0000e+00\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 5.5787 - acc: 0.1875 - val_loss: 22.0877 - val_acc: 0.0000e+00\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0243 - acc: 1.000 - 0s 3ms/step - loss: 5.2119 - acc: 0.1875 - val_loss: 20.8710 - val_acc: 0.0000e+00\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.8903 - acc: 0.1875 - val_loss: 19.6097 - val_acc: 0.0000e+00\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 12.2872 - acc: 0.0000e+ - 0s 2ms/step - loss: 4.5848 - acc: 0.1875 - val_loss: 18.3598 - val_acc: 0.0000e+00\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 4.2621 - acc: 0.1875 - val_loss: 17.3245 - val_acc: 0.0000e+00\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.9827 - acc: 0.1875 - val_loss: 16.3041 - val_acc: 0.0000e+00\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 3.7277 - acc: 0.1875 - val_loss: 15.2662 - val_acc: 0.0000e+00\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.4684 - acc: 0.2500 - val_loss: 14.3364 - val_acc: 0.0000e+00\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 3.2405 - acc: 0.2500 - val_loss: 13.4034 - val_acc: 0.0000e+00\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.9982 - acc: 0.2500 - val_loss: 12.6598 - val_acc: 0.0000e+00\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.8015 - acc: 0.2500 - val_loss: 11.8640 - val_acc: 0.0000e+00\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.6183 - acc: 0.2500 - val_loss: 11.0328 - val_acc: 0.0000e+00\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0204 - acc: 1.000 - 0s 1ms/step - loss: 2.4182 - acc: 0.2500 - val_loss: 10.3388 - val_acc: 0.0000e+00\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.2486 - acc: 0.2500 - val_loss: 9.6705 - val_acc: 0.0000e+00\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 2.0786 - acc: 0.3125 - val_loss: 9.0926 - val_acc: 0.0000e+00\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.9383 - acc: 0.3125 - val_loss: 8.4685 - val_acc: 0.0000e+00\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.7859 - acc: 0.3125 - val_loss: 7.9512 - val_acc: 0.0000e+00\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.6649 - acc: 0.3125 - val_loss: 7.3905 - val_acc: 0.0000e+00\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.5374 - acc: 0.3125 - val_loss: 6.8880 - val_acc: 0.0000e+00\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.4202 - acc: 0.3125 - val_loss: 6.4289 - val_acc: 0.0000e+00\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 1.3121 - acc: 0.3750 - val_loss: 6.0052 - val_acc: 0.0000e+00\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.2136 - acc: 0.3750 - val_loss: 5.6013 - val_acc: 0.0000e+00\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.1196 - acc: 0.3750 - val_loss: 5.2453 - val_acc: 0.0000e+00\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 1.0416 - acc: 0.3750 - val_loss: 4.8546 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.9537 - acc: 0.4375 - val_loss: 4.5336 - val_acc: 0.0000e+00\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.8807 - acc: 0.4375 - val_loss: 4.2280 - val_acc: 0.0000e+00\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.8089 - acc: 0.4375 - val_loss: 3.9795 - val_acc: 0.0000e+00\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.7537 - acc: 0.4375 - val_loss: 3.6845 - val_acc: 0.0000e+00\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6894 - acc: 0.5000 - val_loss: 3.4463 - val_acc: 0.0000e+00\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.6359 - acc: 0.5000 - val_loss: 3.2241 - val_acc: 0.0000e+00\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5874 - acc: 0.5000 - val_loss: 3.0057 - val_acc: 0.0000e+00\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5439 - acc: 0.5000 - val_loss: 2.7875 - val_acc: 0.0000e+00\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.5003 - acc: 0.5625 - val_loss: 2.5943 - val_acc: 0.0000e+00\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4635 - acc: 0.5625 - val_loss: 2.4042 - val_acc: 0.0000e+00\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.4249 - acc: 0.5625 - val_loss: 2.2540 - val_acc: 0.0000e+00\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3949 - acc: 0.5625 - val_loss: 2.0934 - val_acc: 0.0000e+00\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3637 - acc: 0.5625 - val_loss: 1.9557 - val_acc: 0.0000e+00\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.3380 - acc: 0.6250 - val_loss: 1.8191 - val_acc: 0.0000e+00\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.3116 - acc: 0.6250 - val_loss: 1.7064 - val_acc: 0.0000e+00\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2910 - acc: 0.6250 - val_loss: 1.5866 - val_acc: 0.0000e+00\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2703 - acc: 0.6250 - val_loss: 1.4765 - val_acc: 0.0000e+00\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2532 - acc: 0.6875 - val_loss: 1.3680 - val_acc: 0.0000e+00\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2320 - acc: 0.6875 - val_loss: 1.2969 - val_acc: 0.0000e+00\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.2184 - acc: 0.6875 - val_loss: 1.2173 - val_acc: 0.0000e+00\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.2047 - acc: 0.7500 - val_loss: 1.1391 - val_acc: 0.0000e+00\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1927 - acc: 0.7500 - val_loss: 1.0629 - val_acc: 0.0000e+00\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1808 - acc: 0.7500 - val_loss: 0.9962 - val_acc: 0.0000e+00\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1701 - acc: 0.6875 - val_loss: 0.9361 - val_acc: 0.0000e+00\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1607 - acc: 0.7500 - val_loss: 0.8804 - val_acc: 0.0000e+00\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1520 - acc: 0.7500 - val_loss: 0.8402 - val_acc: 0.0000e+00\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1457 - acc: 0.7500 - val_loss: 0.7817 - val_acc: 0.0000e+00\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1378 - acc: 0.7500 - val_loss: 0.7364 - val_acc: 0.0000e+00\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1315 - acc: 0.8125 - val_loss: 0.6983 - val_acc: 0.0000e+00\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1264 - acc: 0.8125 - val_loss: 0.6569 - val_acc: 0.0000e+00\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1210 - acc: 0.8125 - val_loss: 0.6261 - val_acc: 0.0000e+00\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1174 - acc: 0.8125 - val_loss: 0.5844 - val_acc: 0.0000e+00\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1129 - acc: 0.8750 - val_loss: 0.5515 - val_acc: 0.0000e+00\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1089 - acc: 0.8750 - val_loss: 0.5271 - val_acc: 0.0000e+00\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.1059 - acc: 0.8750 - val_loss: 0.5006 - val_acc: 0.0000e+00\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1031 - acc: 0.8750 - val_loss: 0.4757 - val_acc: 0.0000e+00\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.1002 - acc: 0.8750 - val_loss: 0.4547 - val_acc: 0.0000e+00\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0982 - acc: 0.9375 - val_loss: 0.4307 - val_acc: 0.0000e+00\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0961 - acc: 0.9375 - val_loss: 0.4094 - val_acc: 0.0000e+00\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0939 - acc: 0.9375 - val_loss: 0.3935 - val_acc: 0.0000e+00\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0922 - acc: 0.9375 - val_loss: 0.3803 - val_acc: 0.0000e+00\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0909 - acc: 0.9375 - val_loss: 0.3644 - val_acc: 0.0000e+00\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0894 - acc: 0.9375 - val_loss: 0.3533 - val_acc: 0.2500\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0207 - acc: 1.000 - 0s 2ms/step - loss: 0.0883 - acc: 0.9375 - val_loss: 0.3388 - val_acc: 0.2500\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0873 - acc: 0.9375 - val_loss: 0.3237 - val_acc: 0.2500\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0861 - acc: 0.9375 - val_loss: 0.3120 - val_acc: 0.2500\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0852 - acc: 0.9375 - val_loss: 0.3017 - val_acc: 0.2500\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0842 - acc: 0.9375 - val_loss: 0.2957 - val_acc: 0.2500\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0835 - acc: 0.9375 - val_loss: 0.2862 - val_acc: 0.2500\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0829 - acc: 0.9375 - val_loss: 0.2763 - val_acc: 0.5000\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0822 - acc: 0.9375 - val_loss: 0.2674 - val_acc: 0.5000\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0817 - acc: 0.9375 - val_loss: 0.2581 - val_acc: 0.5000\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0809 - acc: 0.9375 - val_loss: 0.2548 - val_acc: 0.5000\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0804 - acc: 0.9375 - val_loss: 0.2510 - val_acc: 0.5000\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0799 - acc: 0.9375 - val_loss: 0.2448 - val_acc: 0.5000\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0794 - acc: 0.9375 - val_loss: 0.2389 - val_acc: 0.5000\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0791 - acc: 0.9375 - val_loss: 0.2309 - val_acc: 0.5000\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0785 - acc: 0.9375 - val_loss: 0.2290 - val_acc: 0.5000\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0781 - acc: 0.9375 - val_loss: 0.2245 - val_acc: 0.7500\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0777 - acc: 0.9375 - val_loss: 0.2186 - val_acc: 0.7500\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0774 - acc: 0.9375 - val_loss: 0.2134 - val_acc: 0.7500\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0770 - acc: 0.9375 - val_loss: 0.2145 - val_acc: 0.7500\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0766 - acc: 0.9375 - val_loss: 0.2087 - val_acc: 0.7500\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0762 - acc: 0.9375 - val_loss: 0.2050 - val_acc: 0.7500\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0758 - acc: 0.9375 - val_loss: 0.2025 - val_acc: 0.7500\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0755 - acc: 0.9375 - val_loss: 0.1982 - val_acc: 0.7500\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0750 - acc: 0.9375 - val_loss: 0.1971 - val_acc: 0.7500\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0748 - acc: 0.9375 - val_loss: 0.1932 - val_acc: 0.7500\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0744 - acc: 0.9375 - val_loss: 0.1928 - val_acc: 0.7500\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0740 - acc: 0.9375 - val_loss: 0.1918 - val_acc: 0.7500\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0737 - acc: 0.9375 - val_loss: 0.1898 - val_acc: 0.7500\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0733 - acc: 0.9375 - val_loss: 0.1879 - val_acc: 0.7500\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0731 - acc: 0.9375 - val_loss: 0.1825 - val_acc: 0.7500\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0726 - acc: 0.9375 - val_loss: 0.1803 - val_acc: 0.7500\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0723 - acc: 0.9375 - val_loss: 0.1806 - val_acc: 0.7500\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0720 - acc: 0.9375 - val_loss: 0.1781 - val_acc: 1.0000\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0716 - acc: 0.9375 - val_loss: 0.1777 - val_acc: 1.0000\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0713 - acc: 0.9375 - val_loss: 0.1757 - val_acc: 1.0000\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0710 - acc: 0.9375 - val_loss: 0.1755 - val_acc: 1.0000\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0706 - acc: 0.9375 - val_loss: 0.1737 - val_acc: 1.0000\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0703 - acc: 0.9375 - val_loss: 0.1713 - val_acc: 1.0000\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0700 - acc: 0.9375 - val_loss: 0.1684 - val_acc: 1.0000\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0696 - acc: 0.9375 - val_loss: 0.1694 - val_acc: 1.0000\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0693 - acc: 1.0000 - val_loss: 0.1673 - val_acc: 1.0000\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0689 - acc: 1.0000 - val_loss: 0.1672 - val_acc: 1.0000\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0685 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 1.0000\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0681 - acc: 1.0000 - val_loss: 0.1648 - val_acc: 1.0000\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0679 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 1.0000\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0675 - acc: 1.0000 - val_loss: 0.1633 - val_acc: 1.0000\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0671 - acc: 1.0000 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0668 - acc: 1.0000 - val_loss: 0.1582 - val_acc: 1.0000\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0664 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 1.0000\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0660 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 1.0000\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0657 - acc: 1.0000 - val_loss: 0.1573 - val_acc: 1.0000\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0654 - acc: 1.0000 - val_loss: 0.1569 - val_acc: 1.0000\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0650 - acc: 1.0000 - val_loss: 0.1533 - val_acc: 1.0000\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0648 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 1.0000\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0643 - acc: 1.0000 - val_loss: 0.1535 - val_acc: 1.0000\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0638 - acc: 1.0000 - val_loss: 0.1521 - val_acc: 1.0000\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0636 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 1.0000\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0632 - acc: 1.0000 - val_loss: 0.1499 - val_acc: 1.0000\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0629 - acc: 1.0000 - val_loss: 0.1500 - val_acc: 1.0000\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0624 - acc: 1.0000 - val_loss: 0.1504 - val_acc: 1.0000\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0621 - acc: 1.0000 - val_loss: 0.1455 - val_acc: 1.0000\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0618 - acc: 1.0000 - val_loss: 0.1474 - val_acc: 1.0000\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0614 - acc: 1.0000 - val_loss: 0.1428 - val_acc: 1.0000\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0609 - acc: 1.0000 - val_loss: 0.1439 - val_acc: 1.0000\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0606 - acc: 1.0000 - val_loss: 0.1424 - val_acc: 1.0000\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0602 - acc: 1.0000 - val_loss: 0.1425 - val_acc: 1.0000\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0600 - acc: 1.0000 - val_loss: 0.1380 - val_acc: 1.0000\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0594 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 1.0000\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0315 - acc: 1.000 - 0s 2ms/step - loss: 0.0590 - acc: 1.0000 - val_loss: 0.1395 - val_acc: 1.0000\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 1.0000\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0583 - acc: 1.0000 - val_loss: 0.1369 - val_acc: 1.0000\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0579 - acc: 1.0000 - val_loss: 0.1370 - val_acc: 1.0000\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0576 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 1.0000\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0572 - acc: 1.0000 - val_loss: 0.1373 - val_acc: 1.0000\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0569 - acc: 1.0000 - val_loss: 0.1327 - val_acc: 1.0000\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0565 - acc: 1.0000 - val_loss: 0.1315 - val_acc: 1.0000\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0562 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 1.0000\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2007 - acc: 1.000 - 0s 2ms/step - loss: 0.0556 - acc: 1.0000 - val_loss: 0.1316 - val_acc: 1.0000\n",
      "Epoch 180/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0552 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 1.0000\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 1.0000\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0545 - acc: 1.0000 - val_loss: 0.1277 - val_acc: 1.0000\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0542 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 1.0000\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0537 - acc: 1.0000 - val_loss: 0.1282 - val_acc: 1.0000\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0534 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 1.0000\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 1.0000\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0526 - acc: 1.0000 - val_loss: 0.1269 - val_acc: 1.0000\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0522 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 1.0000\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0433 - acc: 1.000 - 0s 1ms/step - loss: 0.0518 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 1.0000\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0515 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 1.0000\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0511 - acc: 1.0000 - val_loss: 0.1198 - val_acc: 1.0000\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0507 - acc: 1.0000 - val_loss: 0.1203 - val_acc: 1.0000\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.1201 - val_acc: 1.0000\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0502 - acc: 1.0000 - val_loss: 0.1147 - val_acc: 1.0000\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0495 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 1.0000\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0491 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 1.0000\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.1127 - val_acc: 1.0000\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0483 - acc: 1.0000 - val_loss: 0.1129 - val_acc: 1.0000\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0480 - acc: 1.0000 - val_loss: 0.1129 - val_acc: 1.0000\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0476 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 1.0000\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0472 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 1.0000\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0468 - acc: 1.0000 - val_loss: 0.1125 - val_acc: 1.0000\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0464 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 1.0000\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0460 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 1.0000\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1652 - acc: 1.000 - 0s 1ms/step - loss: 0.0458 - acc: 1.0000 - val_loss: 0.1113 - val_acc: 1.0000\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0454 - acc: 1.0000 - val_loss: 0.1056 - val_acc: 1.0000\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0384 - acc: 1.000 - 0s 1ms/step - loss: 0.0449 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 1.0000\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0445 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 1.0000\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0442 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 1.0000\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0439 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 1.0000\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0435 - acc: 1.0000 - val_loss: 0.1049 - val_acc: 1.0000\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0430 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 1.0000\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0427 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 1.0000\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.0987 - val_acc: 1.0000\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0419 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 1.0000\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.0978 - val_acc: 1.0000\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0412 - acc: 1.0000 - val_loss: 0.0972 - val_acc: 1.0000\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0408 - acc: 1.0000 - val_loss: 0.0966 - val_acc: 1.0000\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 1.0000\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.0949 - val_acc: 1.0000\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0396 - acc: 1.0000 - val_loss: 0.0923 - val_acc: 1.0000\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 1.0000\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 1.0000\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 1.0000\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.0875 - val_acc: 1.0000\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0374 - acc: 1.0000 - val_loss: 0.0859 - val_acc: 1.0000\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 1.0000\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0367 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.0870 - val_acc: 1.0000\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.0841 - val_acc: 1.0000\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0348 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 1.0000\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0344 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0341 - acc: 1.0000 - val_loss: 0.0807 - val_acc: 1.0000\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0337 - acc: 1.0000 - val_loss: 0.0796 - val_acc: 1.0000\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 1.0000\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0172 - acc: 1.000 - 0s 1ms/step - loss: 0.0326 - acc: 1.0000 - val_loss: 0.0780 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.0786 - val_acc: 1.0000\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.0758 - val_acc: 1.0000\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.0757 - val_acc: 1.0000\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0312 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 1.0000\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 1.0000\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.0715 - val_acc: 1.0000\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0060 - acc: 1.000 - 0s 2ms/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 1.0000\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 1.0000\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0295 - acc: 1.0000 - val_loss: 0.0691 - val_acc: 1.0000\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 1.0000\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 1.0000\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.0668 - val_acc: 1.0000\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 1.0000\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 1.0000\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 1.0000\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 1.0000\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.0623 - val_acc: 1.0000\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.0625 - val_acc: 1.0000\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 1.0000\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0610 - val_acc: 1.0000\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0575 - val_acc: 1.0000\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 1.0000\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0132 - acc: 1.000 - 0s 1ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 1.0000\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 1.0000\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.0553 - val_acc: 1.0000\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 1.0000\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 1.0000\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 1.0000\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 1.0000\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 1.0000\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 1.0000\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 1.0000\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 1.0000\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.0463 - val_acc: 1.0000\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 1.0000\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 1.0000\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 1.0000\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.0462 - val_acc: 1.0000\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.0455 - val_acc: 1.0000\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0421 - val_acc: 1.0000\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.0434 - val_acc: 1.0000\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.0396 - val_acc: 1.0000\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 1.0000\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 1.0000\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 1.0000\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 1.0000\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0384 - val_acc: 1.0000\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0356 - val_acc: 1.0000\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 1.0000\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0452 - acc: 1.000 - 0s 1ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 1.0000\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 1.0000\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0354 - val_acc: 1.0000\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 1.0000\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 1.0000\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 하나의 은닉층을 사용하는 경우\n",
    "model = Sequential()\n",
    "print(type(model))\n",
    "# 입력값: input_shape\n",
    "# 출력 노드 갯수: 1개\n",
    "# 활성화 함수: linear\n",
    "# model.add(Dense(1, input_shape=(1,), activation='linear')) # 배열 차원\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))        # 입력 갯수\n",
    "# 학습 설정\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# 학습, validation_split=0.2: 검증 과정에서 4건을 사용, \n",
    "# epochs: 전체 데이터를 대상으로한 학습 횟수\n",
    "# batch_size: 전체데이터를 사용하면 메모리 부족에 시달릴수있어 데이터를\n",
    "# 분할하여 학습, 가중치 변경\n",
    "# 총 가중치 변경: epochs * batch_size\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, \n",
    "                 epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # 가중치 1개 + bias 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 125.0]) # 값을 반영하여 변경\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 은닉층을 사용하는 경우\n",
    "model = Sequential()\n",
    "print(type(model))\n",
    "# 입력값: input_shape\n",
    "# 출력 노드 갯수: 10개\n",
    "# 활성화 함수: linear\n",
    "# model.add(Dense(10, input_shape=(1,), activation='linear')) # 배열 차원\n",
    "model.add(Dense(10, input_dim=1, activation='linear'))        # 입력 갯수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "machine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
